<?xml version='1.0' encoding='UTF-8'?>
<rss version='2.0'>
<channel>
<generator>
clj-rss
</generator>
<link>
https://news.ycombinator.com
</link>
<title>
myread
</title>
<description>
myread
</description>
<item>
<author>
j2kun
</author>
<link>
http://jeremykun.com/2014/01/17/how-to-conquer-tensorphobia/
</link>
<description>
&lt;div&gt;&lt;div class=&quot;entry-content&quot;&gt;
		&lt;p&gt;A professor at Stanford once said,&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;If you really want to impress your friends and confound your enemies, you can invoke &lt;em&gt;tensor products&lt;/em&gt;&amp;#x2026; People run in terror from the &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cotimes&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\otimes&quot; title=&quot;\otimes&quot; class=&quot;latex&quot;&gt; symbol.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;He was explaining some aspects of &lt;a title=&quot;The Two-Dimensional Fourier Transform and Digital Watermarking&quot; href=&quot;http://jeremykun.com/2013/12/30/the-two-dimensional-fourier-transform-and-digital-watermarking/&quot;&gt;multidimensional Fourier transforms&lt;/a&gt;, but this comment is only half in jest; people get confused by tensor products. It&amp;#x2019;s often for good reason. People who really understand tensors feel obligated to explain it using abstract language (specifically, &lt;a title=&quot;Universal Properties&quot; href=&quot;http://jeremykun.com/2013/05/24/universal-properties/&quot;&gt;universal properties&lt;/a&gt;). And the people who explain it in elementary terms don&amp;#x2019;t really understand tensors.&lt;/p&gt;
&lt;p&gt;This post is an attempt to bridge the gap between the elementary and advanced understandings of tensors. We&amp;#x2019;ll start with the elementary (axiomatic) approach, just to get a good feel for the objects we&amp;#x2019;re working with and their essential properties. Then we&amp;#x2019;ll transition to the &amp;#x201C;universal&amp;#x201D; mode of thought, with the express purpose of enlightening us as to why the properties are both necessary and natural.&lt;/p&gt;
&lt;p&gt;But above all, we intend to be sufficiently friendly so as to not make anybody run in fear. This means lots of examples and preferring words over symbols. Unfortunately, we simply can&amp;#x2019;t get by without the reader knowing the very basics of linear algebra (the content of our first two primers on linear algebra &lt;a title=&quot;Linear Algebra &amp;#x2013; A Primer&quot; href=&quot;http://jeremykun.com/2011/06/19/linear-algebra-a-primer/&quot;&gt;(1)&lt;/a&gt; &lt;a title=&quot;Inner Product Spaces &amp;#x2013; A Primer&quot; href=&quot;http://jeremykun.com/2011/07/25/inner-product-spaces-a-primer/&quot;&gt;(2)&lt;/a&gt;, though the only important part of the second is the definition of an inner product).&lt;/p&gt;
&lt;p&gt;So let&amp;#x2019;s begin.&lt;/p&gt;
&lt;h2&gt;Tensors as a Bunch of Axioms&lt;/h2&gt;
&lt;p&gt;Before we get into the thick of things I should clarify some basic terminology.&amp;#xA0;&lt;em&gt;Tensors&lt;/em&gt; are just vectors in a special vector space. We&amp;#x2019;ll see that such a vector space comes about by combining two smaller vector spaces via a&amp;#xA0;&lt;em&gt;tensor product&lt;/em&gt;. So the tensor product is an operation combining vector spaces, and tensors are the elements of the resulting vector space.&lt;/p&gt;
&lt;p&gt;Now the use of the word&amp;#xA0;&lt;em&gt;product&lt;/em&gt; is quite suggestive, and it may lead one to think that a tensor product is similar or related to the usual &lt;em&gt;direct product&lt;/em&gt; of vector spaces. In fact they are related (in very precise sense), but they are far from &lt;em&gt;similar&lt;/em&gt;. If you were pressed, however, you could start with the direct product of two vector spaces and take a mathematical machete to it until it&amp;#x2019;s so disfigured that you have to give it a new name (the tensor product)&lt;span&gt;. &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;With that image in mind let&amp;#x2019;s see how that is done. For the sake of generality we&amp;#x2019;ll talk about two arbitrary finite-dimensional vector spaces &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V%2C+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V, W&quot; title=&quot;V, W&quot; class=&quot;latex&quot;&gt; of dimensions &lt;img src=&quot;http://s0.wp.com/latex.php?latex=n%2C+m&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;n, m&quot; title=&quot;n, m&quot; class=&quot;latex&quot;&gt;.&amp;#xA0;Recall that the &lt;em&gt;direct&amp;#xA0;product&lt;/em&gt;&amp;#xA0; &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V+%5Ctimes+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V \times W&quot; title=&quot;V \times W&quot; class=&quot;latex&quot;&gt; is the vector space of pairs &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%28v%2Cw%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;(v,w)&quot; title=&quot;(v,w)&quot; class=&quot;latex&quot;&gt; where &lt;img src=&quot;http://s0.wp.com/latex.php?latex=v&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;v&quot; title=&quot;v&quot; class=&quot;latex&quot;&gt; comes from &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V&quot; title=&quot;V&quot; class=&quot;latex&quot;&gt; and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=w&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;w&quot; title=&quot;w&quot; class=&quot;latex&quot;&gt; from &lt;img src=&quot;http://s0.wp.com/latex.php?latex=W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;W&quot; title=&quot;W&quot; class=&quot;latex&quot;&gt;. Recall that addition in this vector space is defined componentwise (&lt;img src=&quot;http://s0.wp.com/latex.php?latex=%28v_1%2Cw_1%29+%2B+%28v_2%2C+w_2%29+%3D+%28v_1+%2B+v_2%2C+w_1+%2B+w_2&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;(v_1,w_1) + (v_2, w_2) = (v_1 + v_2, w_1 + w_2&quot; title=&quot;(v_1,w_1) + (v_2, w_2) = (v_1 + v_2, w_1 + w_2&quot; class=&quot;latex&quot;&gt;)) and scalar multiplication scales both components &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Clambda+%28v%2Cw%29+%3D+%28%5Clambda+v%2C+%5Clambda+w%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\lambda (v,w) = (\lambda v, \lambda w)&quot; title=&quot;\lambda (v,w) = (\lambda v, \lambda w)&quot; class=&quot;latex&quot;&gt;.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To get the tensor product space &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V+%5Cotimes+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V \otimes W&quot; title=&quot;V \otimes W&quot; class=&quot;latex&quot;&gt;, we make the following modifications. First, we&amp;#xA0;&lt;em&gt;redefine&lt;/em&gt; what it means to do scalar multiplication. In this brave new tensor world, scalar multiplication of the whole vector-pair is&amp;#xA0;&lt;em&gt;declared&lt;/em&gt; to be the same as scalar multiplication of&amp;#xA0;&lt;em&gt;any component you want&lt;/em&gt;. In symbols,&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clambda+%28v%2C+w%29+%3D+%28%5Clambda+v%2C+w%29+%3D+%28v%2C+%5Clambda+w%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\displaystyle \lambda (v, w) = (\lambda v, w) = (v, \lambda w)&quot; title=&quot;\displaystyle \lambda (v, w) = (\lambda v, w) = (v, \lambda w)&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;for all choices of scalars &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Clambda&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\lambda&quot; title=&quot;\lambda&quot; class=&quot;latex&quot;&gt; and vectors &lt;img src=&quot;http://s0.wp.com/latex.php?latex=v%2C+w&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;v, w&quot; title=&quot;v, w&quot; class=&quot;latex&quot;&gt;. Second, we change the addition operation so that it only works if one of the two components are the same. In symbols, we declare that&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=%28v%2C+w%29+%2B+%28v%27%2C+w%29+%3D+%28v+%2B+v%27%2C+w%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;(v, w) + (v', w) = (v + v', w)&quot; title=&quot;(v, w) + (v', w) = (v + v', w)&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;only works because &lt;img src=&quot;http://s0.wp.com/latex.php?latex=w&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;w&quot; title=&quot;w&quot; class=&quot;latex&quot;&gt; is the same in both pieces, and with the same rule applying if we switch the positions of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=v%2Cw&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;v,w&quot; title=&quot;v,w&quot; class=&quot;latex&quot;&gt; above. All other additions are simply declared to be&amp;#xA0;&lt;em&gt;new&amp;#xA0;&lt;/em&gt;vectors. I.e. &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%28x%2Cy%29+%2B+%28z%2Cw%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;(x,y) + (z,w)&quot; title=&quot;(x,y) + (z,w)&quot; class=&quot;latex&quot;&gt; is simply itself. It&amp;#x2019;s a valid addition &amp;#x2014; we need to be able to add stuff to be a vector space &amp;#x2014; but you just can&amp;#x2019;t combine it any further unless you can use the scalar multiplication to factor out some things so that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=y%3Dw&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;y=w&quot; title=&quot;y=w&quot; class=&quot;latex&quot;&gt; or &lt;img src=&quot;http://s0.wp.com/latex.php?latex=x%3Dz&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;x=z&quot; title=&quot;x=z&quot; class=&quot;latex&quot;&gt;. To say it still one more time, a general element of the tensor &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V+%5Cotimes+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V \otimes W&quot; title=&quot;V \otimes W&quot; class=&quot;latex&quot;&gt; is a sum of these pairs that can or can&amp;#x2019;t be combined by addition (in general things can&amp;#x2019;t always be combined).&lt;/p&gt;
&lt;p&gt;Finally, we&amp;#xA0;&lt;em&gt;rename&lt;/em&gt; the pair &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%28v%2Cw%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;(v,w)&quot; title=&quot;(v,w)&quot; class=&quot;latex&quot;&gt; to &lt;img src=&quot;http://s0.wp.com/latex.php?latex=v+%5Cotimes+w&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;v \otimes w&quot; title=&quot;v \otimes w&quot; class=&quot;latex&quot;&gt;, to distinguish it from the old vector space &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V+%5Ctimes+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V \times W&quot; title=&quot;V \times W&quot; class=&quot;latex&quot;&gt; that we&amp;#x2019;ve totally butchered and reanimated, and we call the tensor product space as a whole &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V+%5Cotimes+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V \otimes W&quot; title=&quot;V \otimes W&quot; class=&quot;latex&quot;&gt;.&amp;#xA0;Those familiar with this kind of abstract algebra will recognize&amp;#xA0;&lt;em&gt;quotient spaces&lt;/em&gt;&amp;#xA0;at work here, but we won&amp;#x2019;t use that language except to note that we cover&amp;#xA0;&lt;a title=&quot;Groups &amp;#x2014; A Primer&quot; href=&quot;http://jeremykun.com/2012/12/08/groups-a-primer/&quot;&gt;quotients&lt;/a&gt;&amp;#xA0;and&amp;#xA0;&lt;a title=&quot;Groups &amp;#x2014; A Second Primer&quot; href=&quot;http://jeremykun.com/2012/12/22/groups-a-second-primer/&quot;&gt;free spaces&lt;/a&gt;&amp;#xA0;elsewhere on this blog, and that&amp;#x2019;s the formality we&amp;#x2019;re ignoring.&lt;/p&gt;
&lt;p&gt;As an example, say we&amp;#x2019;re taking the tensor product of two copies of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\mathbb{R}&quot; title=&quot;\mathbb{R}&quot; class=&quot;latex&quot;&gt;. This means that our space &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D+%5Cotimes+%5Cmathbb%7BR%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\mathbb{R} \otimes \mathbb{R}&quot; title=&quot;\mathbb{R} \otimes \mathbb{R}&quot; class=&quot;latex&quot;&gt; is comprised of vectors like &lt;img src=&quot;http://s0.wp.com/latex.php?latex=3+%5Cotimes+5&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;3 \otimes 5&quot; title=&quot;3 \otimes 5&quot; class=&quot;latex&quot;&gt;, and moreover that the following operations are completely legitimate.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=3+%5Cotimes+5+%2B+1+%5Cotimes+%28-5%29+%3D+3+%5Cotimes+5+%2B+%28-1%29+%5Cotimes+5+%3D+2+%5Cotimes+5&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;3 \otimes 5 + 1 \otimes (-5) = 3 \otimes 5 + (-1) \otimes 5 = 2 \otimes 5&quot; title=&quot;3 \otimes 5 + 1 \otimes (-5) = 3 \otimes 5 + (-1) \otimes 5 = 2 \otimes 5&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=6+%5Cotimes+1+%2B+3%5Cpi+%5Cotimes+%5Cpi+%3D+3+%5Cotimes+2+%2B+3+%5Cotimes+%5Cpi%5E2+%3D+3+%5Cotimes+%282+%2B+%5Cpi%5E2%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;6 \otimes 1 + 3\pi \otimes \pi = 3 \otimes 2 + 3 \otimes \pi^2 = 3 \otimes (2 + \pi^2)&quot; title=&quot;6 \otimes 1 + 3\pi \otimes \pi = 3 \otimes 2 + 3 \otimes \pi^2 = 3 \otimes (2 + \pi^2)&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;Cool. This seemingly innocuous change clearly has huge implications on the structure of the space. We&amp;#x2019;ll get to specifics about how different tensors are from regular products later in this post, but for now we haven&amp;#x2019;t even proved this thing is a vector space. It might not be obvious, but if you go and do the formalities and write the thing as a quotient of a free vector space (as we mentioned we wouldn&amp;#x2019;t do) then you know that quotients of vector spaces are again vector spaces. So we get that one for free. But even without that it should be pretty obvious: we&amp;#x2019;re essentially just&amp;#xA0;&lt;em&gt;declaring&lt;/em&gt; that all the axioms of a vector space hold when we want them to. So if you were wondering whether&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Clambda+%28a+%5Cotimes+b+%2B+c+%5Cotimes+d%29+%3D+%5Clambda%28a+%5Cotimes+b%29+%2B+%5Clambda%28c+%5Cotimes+d%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\lambda (a \otimes b + c \otimes d) = \lambda(a \otimes b) + \lambda(c \otimes d)&quot; title=&quot;\lambda (a \otimes b + c \otimes d) = \lambda(a \otimes b) + \lambda(c \otimes d)&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;The answer is yes, by force of will.&lt;/p&gt;
&lt;p&gt;So just to recall, the axioms of a tensor space &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V+%5Cotimes+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V \otimes W&quot; title=&quot;V \otimes W&quot; class=&quot;latex&quot;&gt; are&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The &amp;#x201C;basic&amp;#x201D; vectors are &lt;img src=&quot;http://s0.wp.com/latex.php?latex=v+%5Cotimes+w&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;v \otimes w&quot; title=&quot;v \otimes w&quot; class=&quot;latex&quot;&gt; for &lt;img src=&quot;http://s0.wp.com/latex.php?latex=v+%5Cin+V%2C+w+%5Cin+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;v \in V, w \in W&quot; title=&quot;v \in V, w \in W&quot; class=&quot;latex&quot;&gt;, and they&amp;#x2019;re used to build up all other vectors.&lt;/li&gt;
&lt;li&gt;Addition is symbolic, unless one of the components is the same in both addends, in which case &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%28v_1%2C+w%29+%2B+%28v_2%2C+w%29+%3D+%28v_1%2B+v_2%2C+w%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;(v_1, w) + (v_2, w) = (v_1+ v_2, w)&quot; title=&quot;(v_1, w) + (v_2, w) = (v_1+ v_2, w)&quot; class=&quot;latex&quot;&gt; and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%28v%2C+w_1%29+%2B+%28v%2Cw_2%29+%3D+%28v%2C+w_1+%2B+w_2%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;(v, w_1) + (v,w_2) = (v, w_1 + w_2)&quot; title=&quot;(v, w_1) + (v,w_2) = (v, w_1 + w_2)&quot; class=&quot;latex&quot;&gt;.&lt;/li&gt;
&lt;li&gt;You can freely move scalar multiples around the components of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=v+%5Cotimes+w&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;v \otimes w&quot; title=&quot;v \otimes w&quot; class=&quot;latex&quot;&gt;.&lt;/li&gt;
&lt;li&gt;The rest of the vector space axioms (distributivity, additive inverses, etc) are assumed with extreme prejudice.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Naturally, one can extend this definition to &lt;img src=&quot;http://s0.wp.com/latex.php?latex=n&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;n&quot; title=&quot;n&quot; class=&quot;latex&quot;&gt;-fold tensor products, like &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V_1+%5Cotimes+V_2+%5Cotimes+%5Cdots+%5Cotimes+V_d&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V_1 \otimes V_2 \otimes \dots \otimes V_d&quot; title=&quot;V_1 \otimes V_2 \otimes \dots \otimes V_d&quot; class=&quot;latex&quot;&gt;. Here we write the vectors as sums of things like &lt;img src=&quot;http://s0.wp.com/latex.php?latex=v_1+%5Cotimes+%5Cdots+%5Cotimes+v_d&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;v_1 \otimes \dots \otimes v_d&quot; title=&quot;v_1 \otimes \dots \otimes v_d&quot; class=&quot;latex&quot;&gt;, and we enforce that addition can only be combined if &lt;em&gt;all but one&lt;/em&gt; coordinates are the same in the addends, and scalar multiples move around to all coordinates equally freely.&lt;/p&gt;
&lt;h2&gt;So where does it come from?!&lt;/h2&gt;
&lt;p&gt;By now we have this definition and we can play with tensors, but any sane mathematically minded person would protest, &amp;#x201C;What the hell would cause anyone to come up with such a definition? I thought mathematics was supposed to be elegant!&amp;#x201D;&lt;/p&gt;
&lt;p&gt;It&amp;#x2019;s an understandable position, but let me now try to convince you that tensor products are very natural. The main intrinsic motivation for the rest of this section will be this:&lt;/p&gt;
&lt;p&gt;We have all these interesting mathematical&amp;#xA0;&lt;em&gt;&lt;/em&gt;objects, but over the years we have discovered that the &lt;em&gt;maps between objects&lt;/em&gt; are the truly interesting things.&lt;/p&gt;
&lt;p&gt;A fair warning: although we&amp;#x2019;ll maintain a gradual pace and informal language in what follows, by the end of this section you&amp;#x2019;ll be reading more or less mature 20th-century mathematics. It&amp;#x2019;s quite alright to stop with the elementary understanding (and skip to the last section for some cool notes about computing), but we trust that the intrepid readers will push on.&lt;/p&gt;
&lt;p&gt;So with that understanding we turn to multilinear maps. Of course, the first substantive thing we study in linear algebra is the notion of a &lt;em&gt;linear map&lt;/em&gt; between vector spaces. That is, a map &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f%3A+V+%5Cto+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f: V \to W&quot; title=&quot;f: V \to W&quot; class=&quot;latex&quot;&gt; that factors through addition and scalar multiplication (i.e. &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f%28v+%2B+v%27%29+%3D+f%28v%29+%2B+f%28v%27%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f(v + v') = f(v) + f(v')&quot; title=&quot;f(v + v') = f(v) + f(v')&quot; class=&quot;latex&quot;&gt; and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f%28%5Clambda+v%29+%3D+%5Clambda+f%28v%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f(\lambda v) = \lambda f(v)&quot; title=&quot;f(\lambda v) = \lambda f(v)&quot; class=&quot;latex&quot;&gt;).&lt;/p&gt;
&lt;p&gt;But it turns out that lots of maps we work with have much stronger properties worth studying. For example, if we think of matrix multiplication as an operation, call it &lt;img src=&quot;http://s0.wp.com/latex.php?latex=m&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;m&quot; title=&quot;m&quot; class=&quot;latex&quot;&gt;, then &lt;img src=&quot;http://s0.wp.com/latex.php?latex=m&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;m&quot; title=&quot;m&quot; class=&quot;latex&quot;&gt; takes in two matrices and spits out their product&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=m%28A%2CB%29+%3D+AB&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;m(A,B) = AB&quot; title=&quot;m(A,B) = AB&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now what would be an appropriate notion of linearity for this map? Certainly it is linear in the first coordinate, because if we fix &lt;img src=&quot;http://s0.wp.com/latex.php?latex=B&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;B&quot; title=&quot;B&quot; class=&quot;latex&quot;&gt; then&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=m%28A%2BC%2C+B%29+%3D+%28A%2BC%29B+%3D+AB+%2B+CB+%3D+m%28A%2CB%29+%2B+m%28C%2CB%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;m(A+C, B) = (A+C)B = AB + CB = m(A,B) + m(C,B)&quot; title=&quot;m(A+C, B) = (A+C)B = AB + CB = m(A,B) + m(C,B)&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;And for the same reason it&amp;#x2019;s linear in the second coordinate. But it is most definitely not linear in both coordinates &lt;em&gt;simultaneously.&amp;#xA0;&lt;/em&gt;In other words,&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=m%28A%2BB%2C+C%2BD%29+%3D+%28A%2BB%29%28C%2BD%29+%3D+AC+%2B+AD+%2B+BC+%2B+BD+%5Cneq+AC+%2B+BD+%3D+m%28A%2CC%29+%2B+m%28B%2CD%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;m(A+B, C+D) = (A+B)(C+D) = AC + AD + BC + BD \neq AC + BD = m(A,C) + m(B,D)&quot; title=&quot;m(A+B, C+D) = (A+B)(C+D) = AC + AD + BC + BD \neq AC + BD = m(A,C) + m(B,D)&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;In fact, if the&lt;em&gt; only&lt;/em&gt; operation satisfying linearity in its two coordinates separately and also this kind of linearity is the zero map! (Try to prove this as an exercise.)&amp;#xA0;So the strongest kind of linearity we could reasonably impose is that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=m&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;m&quot; title=&quot;m&quot; class=&quot;latex&quot;&gt; is linear in each coordinate when &lt;strong&gt;all else is fixed&lt;/strong&gt;. Note that this property allows us to shift around scalar multiples, too. For example,&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cdisplaystyle+m%28%5Clambda+A%2C+B%29+%3D+%5Clambda+AB+%3D+A+%28%5Clambda+B%29+%3D+m%28A%2C+%5Clambda+B%29+%3D+%5Clambda+m%28A%2CB%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\displaystyle m(\lambda A, B) = \lambda AB = A (\lambda B) = m(A, \lambda B) = \lambda m(A,B)&quot; title=&quot;\displaystyle m(\lambda A, B) = \lambda AB = A (\lambda B) = m(A, \lambda B) = \lambda m(A,B)&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;Starting to see the wispy strands of a connection to tensors? Good, but hold it in for a bit longer. This single-coordinate-wise-linear property is called&amp;#xA0;&lt;em&gt;bilinearity&amp;#xA0;&lt;/em&gt;when we only have two coordinates, and&amp;#xA0;&lt;em&gt;multilinearity&lt;/em&gt; when we have more.&lt;/p&gt;
&lt;p&gt;Here are some examples of nice multilinear maps that show up everywhere:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V&quot; title=&quot;V&quot; class=&quot;latex&quot;&gt; is an inner product space over &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\mathbb{R}&quot; title=&quot;\mathbb{R}&quot; class=&quot;latex&quot;&gt;, then the inner product is bilinear.&lt;/li&gt;
&lt;li&gt;The determinant of a matrix is a multilinear map if we view the columns of the matrix as vector arguments.&lt;/li&gt;
&lt;li&gt;The cross product of vectors in &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E3&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\mathbb{R}^3&quot; title=&quot;\mathbb{R}^3&quot; class=&quot;latex&quot;&gt; is bilinear.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are many other examples, but you should have at least passing familiarity with these notions, and it&amp;#x2019;s enough to convince us that multilinearity is worth studying abstractly.&lt;/p&gt;
&lt;p&gt;And so what tensors do is give a sort of &lt;em&gt;classification&lt;/em&gt; of multilinear maps. The idea is that every multilinear map &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f&quot; title=&quot;f&quot; class=&quot;latex&quot;&gt; from a product vector space &lt;img src=&quot;http://s0.wp.com/latex.php?latex=U_1+%5Ctimes+%5Cdots+%5Ctimes+U_d&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;U_1 \times \dots \times U_d&quot; title=&quot;U_1 \times \dots \times U_d&quot; class=&quot;latex&quot;&gt; to any vector space &lt;img src=&quot;http://s0.wp.com/latex.php?latex=Y&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;Y&quot; title=&quot;Y&quot; class=&quot;latex&quot;&gt; can be written first as a multilinear map to the tensor space&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Calpha+%3A+U_1+%5Ctimes+%5Cdots+%5Ctimes+U_d+%5Cto+U_1+%5Cotimes+%5Cdots+%5Cotimes+U_d&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\displaystyle \alpha : U_1 \times \dots \times U_d \to U_1 \otimes \dots \otimes U_d&quot; title=&quot;\displaystyle \alpha : U_1 \times \dots \times U_d \to U_1 \otimes \dots \otimes U_d&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;Followed by a linear map to &lt;img src=&quot;http://s0.wp.com/latex.php?latex=Y&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;Y&quot; title=&quot;Y&quot; class=&quot;latex&quot;&gt;,&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Chat%7Bf%7D+%3A+U_1+%5Cotimes+%5Cdots+%5Cotimes+U_d+%5Cto+Y&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\displaystyle \hat{f} : U_1 \otimes \dots \otimes U_d \to Y&quot; title=&quot;\displaystyle \hat{f} : U_1 \otimes \dots \otimes U_d \to Y&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;And the important part is that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Calpha&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\alpha&quot; title=&quot;\alpha&quot; class=&quot;latex&quot;&gt; doesn&amp;#x2019;t depend on the original &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f&quot; title=&quot;f&quot; class=&quot;latex&quot;&gt; (but &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\hat{f}&quot; title=&quot;\hat{f}&quot; class=&quot;latex&quot;&gt; does). One usually draws this as a single diagram:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jeremykun.files.wordpress.com/2014/01/comm-diagram-tensor.png&quot;&gt;&lt;img class=&quot;aligncenter  wp-image-4432&quot; alt=&quot;comm-diagram-tensor&quot; src=&quot;http://jeremykun.files.wordpress.com/2014/01/comm-diagram-tensor.png?w=519&amp;amp;h=355&quot; width=&quot;519&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And to say this diagram &lt;em&gt;commutes&lt;/em&gt; is to say that all possible ways to get from one point to another are equivalent (the compositions of the corresponding maps you follow are equal, i.e. &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f+%3D+%5Chat%7Bf%7D+%5Calpha&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f = \hat{f} \alpha&quot; title=&quot;f = \hat{f} \alpha&quot; class=&quot;latex&quot;&gt;).&lt;/p&gt;
&lt;p&gt;In fuzzy words, the tensor product is like the gatekeeper of all multilinear maps, and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Calpha&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\alpha&quot; title=&quot;\alpha&quot; class=&quot;latex&quot;&gt; is the gate. Yet another way to say this is that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Calpha&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\alpha&quot; title=&quot;\alpha&quot; class=&quot;latex&quot;&gt; is the most general possible multilinear map that can be constructed from &lt;img src=&quot;http://s0.wp.com/latex.php?latex=U_1+%5Ctimes+%5Cdots+%5Ctimes+U_d&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;U_1 \times \dots \times U_d&quot; title=&quot;U_1 \times \dots \times U_d&quot; class=&quot;latex&quot;&gt;. Moreover, the tensor product itself is &lt;i&gt;uniquely&lt;/i&gt; defined by having a &amp;#x201C;most-general&amp;#x201D; &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Calpha&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\alpha&quot; title=&quot;\alpha&quot; class=&quot;latex&quot;&gt; (up to isomorphism). This notion is often referred to by mathematicians as the &amp;#x201C;universal property&amp;#x201D; of the tensor product. And they might say something like &amp;#x201C;the tensor product is initial with respect to multilinear mappings from the standard product.&amp;#x201D; We discuss language like this in detail in this blog&amp;#x2019;s series on &lt;a title=&quot;Introducing Categories&quot; href=&quot;http://jeremykun.com/2013/04/24/introducing-categories/&quot;&gt;category theory&lt;/a&gt;, but it&amp;#x2019;s essentially a super-compact (and almost too vague) way of saying what the diagram says.&lt;/p&gt;
&lt;p&gt;Let&amp;#x2019;s explore this definition when we specialize to a tensor of two vector spaces, and it will give us a good understanding of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Calpha&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\alpha&quot; title=&quot;\alpha&quot; class=&quot;latex&quot;&gt; (which is really incredibly simple, but people like to muck it up with choices of coordinates and summations). So fix &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V%2C+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V, W&quot; title=&quot;V, W&quot; class=&quot;latex&quot;&gt; as vector spaces and look at the diagram&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jeremykun.files.wordpress.com/2014/01/comm-diagram-tensor-2.png&quot;&gt;&lt;img class=&quot;aligncenter size-full wp-image-4431&quot; alt=&quot;comm-diagram-tensor-2&quot; src=&quot;http://jeremykun.files.wordpress.com/2014/01/comm-diagram-tensor-2.png?w=1800&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;What is &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Calpha&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\alpha&quot; title=&quot;\alpha&quot; class=&quot;latex&quot;&gt; in this case? Well it just sends &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%28v%2Cw%29+%5Cmapsto+v+%5Cotimes+w&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;(v,w) \mapsto v \otimes w&quot; title=&quot;(v,w) \mapsto v \otimes w&quot; class=&quot;latex&quot;&gt;. Is this map multilinear? Well if we fix &lt;img src=&quot;http://s0.wp.com/latex.php?latex=w&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;w&quot; title=&quot;w&quot; class=&quot;latex&quot;&gt; then&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Calpha%28v_1+%2B+v_2%2C+w%29+%3D+%28v_1+%2B+v_2%29+%5Cotimes+w+%3D+v_1+%5Cotimes+w+%2B+v_2+%5Cotimes+w+%3D+%5Calpha%28v_1%2C+w%29+%2B+%5Calpha+%28v_2%2C+w%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\displaystyle \alpha(v_1 + v_2, w) = (v_1 + v_2) \otimes w = v_1 \otimes w + v_2 \otimes w = \alpha(v_1, w) + \alpha (v_2, w)&quot; title=&quot;\displaystyle \alpha(v_1 + v_2, w) = (v_1 + v_2) \otimes w = v_1 \otimes w + v_2 \otimes w = \alpha(v_1, w) + \alpha (v_2, w)&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Calpha%28%5Clambda+v%2C+w%29+%3D+%28%5Clambda+v%29+%5Cotimes+w+%3D+%28%5Clambda%29+%28v+%5Cotimes+w%29+%3D+%5Clambda+%5Calpha%28v%2Cw%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\displaystyle \alpha(\lambda v, w) = (\lambda v) \otimes w = (\lambda) (v \otimes w) = \lambda \alpha(v,w)&quot; title=&quot;\displaystyle \alpha(\lambda v, w) = (\lambda v) \otimes w = (\lambda) (v \otimes w) = \lambda \alpha(v,w)&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;And our familiarity with tensors now tells us that the other side holds too. Actually, rather than say this is a result of our &amp;#x201C;familiarity with tensors,&amp;#x201D; the truth is that this is how we know that we need to define the properties of tensors as we did. It&amp;#x2019;s all because we &lt;em&gt;designed&lt;/em&gt; tensors to be the gatekeepers of multilinear maps!&lt;/p&gt;
&lt;p&gt;So now let&amp;#x2019;s prove that all maps &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f+%3A+V+%5Ctimes+W+%5Cto+Y&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f : V \times W \to Y&quot; title=&quot;f : V \times W \to Y&quot; class=&quot;latex&quot;&gt; can be decomposed into an &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Calpha&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\alpha&quot; title=&quot;\alpha&quot; class=&quot;latex&quot;&gt; part and a &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\hat{f}&quot; title=&quot;\hat{f}&quot; class=&quot;latex&quot;&gt; part. To do this we need to know what data uniquely defines a multilinear map. For usual linear maps, all we had to do was define the effect of the map on each element of a basis (the rest was uniquely determined by the linearity property). We know what a basis of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V+%5Ctimes+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V \times W&quot; title=&quot;V \times W&quot; class=&quot;latex&quot;&gt; is, it&amp;#x2019;s just the union of the bases of the pieces. Say that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V&quot; title=&quot;V&quot; class=&quot;latex&quot;&gt; has a basis &lt;img src=&quot;http://s0.wp.com/latex.php?latex=v_1%2C+%5Cdots%2C+v_n&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;v_1, \dots, v_n&quot; title=&quot;v_1, \dots, v_n&quot; class=&quot;latex&quot;&gt; and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;W&quot; title=&quot;W&quot; class=&quot;latex&quot;&gt; has &lt;img src=&quot;http://s0.wp.com/latex.php?latex=w_1%2C+%5Cdots%2C+w_m&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;w_1, \dots, w_m&quot; title=&quot;w_1, \dots, w_m&quot; class=&quot;latex&quot;&gt;, then a basis for the product is just &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%28%28v_1%2C+0%29%2C+%5Cdots%2C+%28v_n%2C0%29%2C+%280%2Cw_1%29%2C+%5Cdots%2C+%280%2Cw_m%29%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;((v_1, 0), \dots, (v_n,0), (0,w_1), \dots, (0,w_m))&quot; title=&quot;((v_1, 0), \dots, (v_n,0), (0,w_1), \dots, (0,w_m))&quot; class=&quot;latex&quot;&gt;.&lt;/p&gt;
&lt;p&gt;But multilinear maps are more nuanced, because they have two arguments. In order to say &amp;#x201C;what they do on a basis&amp;#x201D; we really need to know how they act on&amp;#xA0;&lt;em&gt;all possible pairs&amp;#xA0;&lt;/em&gt;of basis elements.&amp;#xA0;For how else could we determine &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f%28v_1+%2B+v_2%2C+w_1%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f(v_1 + v_2, w_1)&quot; title=&quot;f(v_1 + v_2, w_1)&quot; class=&quot;latex&quot;&gt;? If there are &lt;img src=&quot;http://s0.wp.com/latex.php?latex=n&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;n&quot; title=&quot;n&quot; class=&quot;latex&quot;&gt; of the &lt;img src=&quot;http://s0.wp.com/latex.php?latex=v_i&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;v_i&quot; title=&quot;v_i&quot; class=&quot;latex&quot;&gt;&amp;#x2018;s and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=m&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;m&quot; title=&quot;m&quot; class=&quot;latex&quot;&gt; of the &lt;img src=&quot;http://s0.wp.com/latex.php?latex=w_i&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;w_i&quot; title=&quot;w_i&quot; class=&quot;latex&quot;&gt;&amp;#x2018;s, then there are &lt;img src=&quot;http://s0.wp.com/latex.php?latex=nm&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;nm&quot; title=&quot;nm&quot; class=&quot;latex&quot;&gt; such pairs &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f%28v_i%2C+w_j%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f(v_i, w_j)&quot; title=&quot;f(v_i, w_j)&quot; class=&quot;latex&quot;&gt;.&lt;/p&gt;
&lt;p&gt;Uncoincidentally, as &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V+%5Cotimes+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V \otimes W&quot; title=&quot;V \otimes W&quot; class=&quot;latex&quot;&gt; is a vector space,&amp;#xA0;&lt;em&gt;its&lt;/em&gt; basis can also be constructed in terms of the bases of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V&quot; title=&quot;V&quot; class=&quot;latex&quot;&gt; and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;W&quot; title=&quot;W&quot; class=&quot;latex&quot;&gt;. You simply take all possible tensors &lt;img src=&quot;http://s0.wp.com/latex.php?latex=v_i+%5Cotimes+w_j&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;v_i \otimes w_j&quot; title=&quot;v_i \otimes w_j&quot; class=&quot;latex&quot;&gt;. Since every &lt;img src=&quot;http://s0.wp.com/latex.php?latex=v+%5Cin+V%2C+w+%5Cin+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;v \in V, w \in W&quot; title=&quot;v \in V, w \in W&quot; class=&quot;latex&quot;&gt; can be written in terms of their bases, it&amp;#x2019;s clear than any tensor &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Csum_%7Bk%7D+a_k+%5Cotimes+b_k&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\sum_{k} a_k \otimes b_k&quot; title=&quot;\sum_{k} a_k \otimes b_k&quot; class=&quot;latex&quot;&gt; can also be written in terms of the basis tensors &lt;img src=&quot;http://s0.wp.com/latex.php?latex=v_i+%5Cotimes+w_j&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;v_i \otimes w_j&quot; title=&quot;v_i \otimes w_j&quot; class=&quot;latex&quot;&gt; (by simply expanding each &lt;img src=&quot;http://s0.wp.com/latex.php?latex=a_k%2C+b_k&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;a_k, b_k&quot; title=&quot;a_k, b_k&quot; class=&quot;latex&quot;&gt; in terms of their respective bases, and getting a larger sum of more basic tensors).&lt;/p&gt;
&lt;p&gt;Just to drive this point home, if &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%28e_1%2C+e_2%2C+e_3%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;(e_1, e_2, e_3)&quot; title=&quot;(e_1, e_2, e_3)&quot; class=&quot;latex&quot;&gt; is a basis for &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E3&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\mathbb{R}^3&quot; title=&quot;\mathbb{R}^3&quot; class=&quot;latex&quot;&gt;, and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%28g_1%2C+g_2%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;(g_1, g_2)&quot; title=&quot;(g_1, g_2)&quot; class=&quot;latex&quot;&gt; a basis for &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E2&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\mathbb{R}^2&quot; title=&quot;\mathbb{R}^2&quot; class=&quot;latex&quot;&gt;, then the tensor space &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E3+%5Cotimes+%5Cmathbb%7BR%7D%5E2&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\mathbb{R}^3 \otimes \mathbb{R}^2&quot; title=&quot;\mathbb{R}^3 \otimes \mathbb{R}^2&quot; class=&quot;latex&quot;&gt; has basis&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=%28e_1+%5Cotimes+g_1%2C+e_1+%5Cotimes+g_2%2C+e_2+%5Cotimes+g_1%2C+e_2+%5Cotimes+g_2%2C+e_3+%5Cotimes+g_1%2C+e_3+%5Cotimes+g_2%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;(e_1 \otimes g_1, e_1 \otimes g_2, e_2 \otimes g_1, e_2 \otimes g_2, e_3 \otimes g_1, e_3 \otimes g_2)&quot; title=&quot;(e_1 \otimes g_1, e_1 \otimes g_2, e_2 \otimes g_1, e_2 \otimes g_2, e_3 \otimes g_1, e_3 \otimes g_2)&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;It&amp;#x2019;s a theorem that finite-dimensional vector spaces of equal dimension are isomorphic, so the length of this basis (6) tells us that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E3+%5Cotimes+%5Cmathbb%7BR%7D%5E2+%5Ccong+%5Cmathbb%7BR%7D%5E6&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\mathbb{R}^3 \otimes \mathbb{R}^2 \cong \mathbb{R}^6&quot; title=&quot;\mathbb{R}^3 \otimes \mathbb{R}^2 \cong \mathbb{R}^6&quot; class=&quot;latex&quot;&gt;.&lt;/p&gt;
&lt;p&gt;So fine, back to decomposing &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f&quot; title=&quot;f&quot; class=&quot;latex&quot;&gt;. All we have left to do is use the data given by &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f&quot; title=&quot;f&quot; class=&quot;latex&quot;&gt; (the effect on pairs of basis elements) to define &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D+%3A+V+%5Cotimes+W+%5Cto+Y&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\hat{f} : V \otimes W \to Y&quot; title=&quot;\hat{f} : V \otimes W \to Y&quot; class=&quot;latex&quot;&gt;. The definition is rather straightforward, as we have already made the suggestive move of showing that the basis for the tensor space (&lt;img src=&quot;http://s0.wp.com/latex.php?latex=v_i+%5Cotimes+w_j&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;v_i \otimes w_j&quot; title=&quot;v_i \otimes w_j&quot; class=&quot;latex&quot;&gt;) and the definition of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f&quot; title=&quot;f&quot; class=&quot;latex&quot;&gt; (&lt;img src=&quot;http://s0.wp.com/latex.php?latex=f%28v_i%2C+w_j%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f(v_i, w_j)&quot; title=&quot;f(v_i, w_j)&quot; class=&quot;latex&quot;&gt;) are essentially the same.&lt;/p&gt;
&lt;p&gt;That is, just take &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D%28v_i+%5Cotimes+w_j%29+%3D+f%28v_i%2C+w_j%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\hat{f}(v_i \otimes w_j) = f(v_i, w_j)&quot; title=&quot;\hat{f}(v_i \otimes w_j) = f(v_i, w_j)&quot; class=&quot;latex&quot;&gt;. Note that this is just defined on the basis elements, and so we extend to all other vectors in the tensor space by imposing linearity (defining &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\hat{f}&quot; title=&quot;\hat{f}&quot; class=&quot;latex&quot;&gt; to split across sums of tensors as needed). Is this well defined? Well, multilinearity of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f&quot; title=&quot;f&quot; class=&quot;latex&quot;&gt; forces it to be so. For if we had two equal tensors, say, &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Clambda+v+%5Cotimes+w+%3D+v+%5Cotimes+%5Clambda+w&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\lambda v \otimes w = v \otimes \lambda w&quot; title=&quot;\lambda v \otimes w = v \otimes \lambda w&quot; class=&quot;latex&quot;&gt;, then we know that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f&quot; title=&quot;f&quot; class=&quot;latex&quot;&gt; has to respect their equality, because &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f%28%5Clambda+v_i%2C+w_j%29+%3D+f%28v_i%2C+%5Clambda+w_j%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f(\lambda v_i, w_j) = f(v_i, \lambda w_j)&quot; title=&quot;f(\lambda v_i, w_j) = f(v_i, \lambda w_j)&quot; class=&quot;latex&quot;&gt;, so &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\hat{f}&quot; title=&quot;\hat{f}&quot; class=&quot;latex&quot;&gt; will take the same value on equal tensors regardless of which representative we pick (where we decide to put the &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Clambda&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\lambda&quot; title=&quot;\lambda&quot; class=&quot;latex&quot;&gt;). The same idea works for sums, so everything checks out, and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f%28v%2Cw%29&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;f(v,w)&quot; title=&quot;f(v,w)&quot; class=&quot;latex&quot;&gt; is equal to &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D+%5Calpha&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\hat{f} \alpha&quot; title=&quot;\hat{f} \alpha&quot; class=&quot;latex&quot;&gt;, as desired. Moreover, we didn&amp;#x2019;t make any choices in constructing &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\hat{f}&quot; title=&quot;\hat{f}&quot; class=&quot;latex&quot;&gt;. If you retrace our steps in the argument, you&amp;#x2019;ll see that everything was essentially decided for us once we fixed a choice of a basis (by our wise decisions in defining &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V+%5Cotimes+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V \otimes W&quot; title=&quot;V \otimes W&quot; class=&quot;latex&quot;&gt;). Since the construction would be isomorphic if we changed the basis, our choice of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Chat%7Bf%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\hat{f}&quot; title=&quot;\hat{f}&quot; class=&quot;latex&quot;&gt; is unique.&lt;/p&gt;
&lt;p&gt;There is a lot more to say about tensors, and indeed there are some other useful ways to think about tensors that we&amp;#x2019;ve completely ignored. But this discussion should make it clear&amp;#xA0;&lt;em&gt;why&lt;/em&gt;&amp;#xA0;we define tensors the way we do. Hopefully it eliminates most of the mystery in tensors, although there is still a lot of mystery in trying to compute stuff using tensors. So we&amp;#x2019;ll wrap up this post with a short discussion about that.&lt;/p&gt;
&lt;h2&gt;Computability and Stuff&lt;/h2&gt;
&lt;p&gt;It should be clear by now that plain product spaces &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V+%5Ctimes+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V \times W&quot; title=&quot;V \times W&quot; class=&quot;latex&quot;&gt; and tensor product spaces &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V+%5Cotimes+W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V \otimes W&quot; title=&quot;V \otimes W&quot; class=&quot;latex&quot;&gt; are extremely different. In fact, they&amp;#x2019;re only related in that their underlying sets of vectors are built from pairs of vectors in &lt;img src=&quot;http://s0.wp.com/latex.php?latex=V&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;V&quot; title=&quot;V&quot; class=&quot;latex&quot;&gt; and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=W&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;W&quot; title=&quot;W&quot; class=&quot;latex&quot;&gt;.&amp;#xA0;Avid readers of this blog will also know that operations involving matrices (like &lt;a title=&quot;Row Reduction Over A Field&quot; href=&quot;http://jeremykun.com/2011/12/30/row-reduction-over-a-field/&quot;&gt;row reduction&lt;/a&gt;, &lt;a title=&quot;Eigenfaces, for Facial Recognition&quot; href=&quot;http://jeremykun.com/2011/07/27/eigenfaces/&quot;&gt;eigenvalue computations&lt;/a&gt;, etc.) are generally efficient, or at least they run in polynomial time so they&amp;#x2019;re not crazy impractically slow for modest inputs.&lt;/p&gt;
&lt;p&gt;On the other hand, it turns out that almost every question you might want to ask about tensors is difficult to answer computationally. As with the definition of the tensor product, this is no mere coincidence. There is something deep going on with tensors, and it has serious implications regarding quantum computing. More on that in a future post, but for now let&amp;#x2019;s just focus on one hard problem to answer for tensors.&lt;/p&gt;
&lt;p&gt;As you know, the most general way to write an element of a tensor space &lt;img src=&quot;http://s0.wp.com/latex.php?latex=U_1+%5Cotimes+%5Cdots+%5Cotimes+U_d&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;U_1 \otimes \dots \otimes U_d&quot; title=&quot;U_1 \otimes \dots \otimes U_d&quot; class=&quot;latex&quot;&gt; is as a sum of the basic-looking tensors.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bk%7D+a_%7B1%2Ck%7D+%5Cotimes+a_%7B2%2Ck%7D+%5Cotimes+%5Cdots+%5Cotimes+a_%7Bd%2Ck%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\displaystyle \sum_{k} a_{1,k} \otimes a_{2,k} \otimes \dots \otimes a_{d,k}&quot; title=&quot;\displaystyle \sum_{k} a_{1,k} \otimes a_{2,k} \otimes \dots \otimes a_{d,k}&quot; class=&quot;latex&quot;&gt;&lt;/p&gt;
&lt;p&gt;where the &lt;img src=&quot;http://s0.wp.com/latex.php?latex=a_%7Bi%2Ck%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;a_{i,k}&quot; title=&quot;a_{i,k}&quot; class=&quot;latex&quot;&gt; may be sums of vectors from &lt;img src=&quot;http://s0.wp.com/latex.php?latex=U_i&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;U_i&quot; title=&quot;U_i&quot; class=&quot;latex&quot;&gt; themselves. But as we saw with our examples over &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\mathbb{R}&quot; title=&quot;\mathbb{R}&quot; class=&quot;latex&quot;&gt;, there can be lots of different ways to write a tensor. If you&amp;#x2019;re lucky, you can write the entire tensor as a one-term sum, that is just a tensor &lt;img src=&quot;http://s0.wp.com/latex.php?latex=a+%5Cotimes+b&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;a \otimes b&quot; title=&quot;a \otimes b&quot; class=&quot;latex&quot;&gt;. If you can do this we call the tensor a&amp;#xA0;&lt;em&gt;pure tensor,&lt;/em&gt; or a &lt;em&gt;rank 1 tensor&lt;/em&gt;. We then have the following natural definition and problem:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Definition:&amp;#xA0;&lt;/strong&gt;The&amp;#xA0;&lt;em&gt;rank&amp;#xA0;&lt;/em&gt;of a tensor &lt;img src=&quot;http://s0.wp.com/latex.php?latex=x+%5Cin+U_1+%5Cotimes+%5Cdots+%5Cotimes+U_d&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;x \in U_1 \otimes \dots \otimes U_d&quot; title=&quot;x \in U_1 \otimes \dots \otimes U_d&quot; class=&quot;latex&quot;&gt; is the minimum number of terms in any representation of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=x&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;x&quot; title=&quot;x&quot; class=&quot;latex&quot;&gt; as a sum of pure tensors. The one exception is the zero element, which has rank zero by convention.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Given a tensor &lt;img src=&quot;http://s0.wp.com/latex.php?latex=x+%5Cin+k%5E%7Bn_1%7D+%5Cotimes+k%5E%7Bn_2%7D+%5Cotimes+k%5E%7Bn_3%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;x \in k^{n_1} \otimes k^{n_2} \otimes k^{n_3}&quot; title=&quot;x \in k^{n_1} \otimes k^{n_2} \otimes k^{n_3}&quot; class=&quot;latex&quot;&gt; where &lt;img src=&quot;http://s0.wp.com/latex.php?latex=k&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;k&quot; title=&quot;k&quot; class=&quot;latex&quot;&gt; is a field, compute its rank.&lt;/p&gt;
&lt;p&gt;Of course this isn&amp;#x2019;t possible in standard computing models unless you can represent the elements of the field (and hence the elements of the vector space in question) in a computer program. So we restrict &lt;img src=&quot;http://s0.wp.com/latex.php?latex=k&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;k&quot; title=&quot;k&quot; class=&quot;latex&quot;&gt; to be either the rational numbers &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BQ%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\mathbb{Q}&quot; title=&quot;\mathbb{Q}&quot; class=&quot;latex&quot;&gt; or a finite field &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D_%7Bq%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\mathbb{F}_{q}&quot; title=&quot;\mathbb{F}_{q}&quot; class=&quot;latex&quot;&gt;.&lt;/p&gt;
&lt;p&gt;Even though the problem is simple to state, it was proved in 1990 (a result of &lt;a href=&quot;http://www.nada.kth.se/~johanh/&quot;&gt;Johan H&amp;#xE5;stad&lt;/a&gt;) that tensor rank is hard to compute. Specifically, the theorem is that&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem:&lt;/strong&gt;&amp;#xA0;Computing tensor rank is NP-hard when &lt;img src=&quot;http://s0.wp.com/latex.php?latex=k+%3D+%5Cmathbb%7BQ%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;k = \mathbb{Q}&quot; title=&quot;k = \mathbb{Q}&quot; class=&quot;latex&quot;&gt; and NP-complete when &lt;img src=&quot;http://s0.wp.com/latex.php?latex=k&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;k&quot; title=&quot;k&quot; class=&quot;latex&quot;&gt; is a finite field.&lt;/p&gt;
&lt;p&gt;The details are given in &lt;a href=&quot;http://www.nada.kth.se/~johanh/tensorrank.pdf&quot;&gt;H&amp;#xE5;stad&amp;#x2019;s&amp;#xA0;paper&lt;/a&gt;, but the important work that followed essentially showed that most problems involving tensors are hard to compute (many of them by reduction from computing rank). This is unfortunate, but also displays the power of tensors. In fact, tensors are &lt;a href=&quot;http://www.its.caltech.edu/~matilde/WeitzMa10Abstract.pdf&quot;&gt;so powerful&lt;/a&gt;&amp;#xA0;that many believe understanding them better will lead to insight in some very important problems, like finding faster matrix multiplication algorithms or proving circuit lower bounds (which is closely related to &lt;a title=&quot;P vs. NP, A Primer (And a Proof Written in Racket)&quot; href=&quot;http://jeremykun.com/2012/02/23/p-vs-np-a-primer-and-a-proof-written-in-racket/&quot;&gt;P vs NP&lt;/a&gt;). Finding low-rank tensor approximations is also a key technique in a lot of recent machine learning and data mining algorithms.&lt;/p&gt;
&lt;p&gt;With this in mind, the enterprising reader will probably agree that understanding tensors is both valuable and useful. In the future of this blog we&amp;#x2019;ll hope to see some of these techniques, but at the very least we&amp;#x2019;ll see the return of tensors when we delve into quantum computing.&lt;/p&gt;
&lt;p&gt;Until next time!&lt;/p&gt;
		&lt;div id=&quot;jp-post-flair&quot; class=&quot;sharedaddy sd-like-enabled sd-sharing-enabled&quot;&gt;&lt;div class=&quot;sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-unloaded&quot; id=&quot;like-post-wrapper-23934684-4415-52e438bf9eb09&quot;&gt;&lt;h3 class=&quot;sd-title&quot;&gt;Like this:&lt;/h3&gt;&lt;p class=&quot;likes-widget-placeholder post-likes-widget-placeholder&quot;&gt;&lt;span class=&quot;button&quot;&gt;&lt;span&gt;Like&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;loading&quot;&gt;Loading...&lt;/span&gt;&lt;/p&gt;&lt;a class=&quot;sd-link-color&quot;&gt;&lt;/a&gt;&lt;/div&gt;
&lt;p id=&quot;jp-relatedposts&quot; class=&quot;jp-relatedposts&quot;&gt;
	&lt;h3 class=&quot;jp-relatedposts-headline&quot;&gt;&lt;em&gt;Related&lt;/em&gt;&lt;/h3&gt;
&lt;/p&gt;&lt;/div&gt;			&lt;/div&gt;

	
&lt;/div&gt;
</description>
<title>
How to Conquer Tensorphobia
</title>
</item>
<item>
<author>
Tom Nichols
</author>
<link>
http://thefederalist.com/2014/01/17/the-death-of-expertise
</link>
<description>
&lt;div&gt;&lt;div class=&quot;entry-content clearfix&quot;&gt;&lt;div&gt;&lt;p&gt;I am (or at least think I am) an expert. Not on everything, but in a particular area of human knowledge, specifically social science and public policy. When I say something on those subjects, I expect that my opinion holds more weight than that of most other people.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;I never thought those were particularly controversial statements. As it turns out, they&amp;#x2019;re plenty controversial. Today, any assertion of expertise produces an explosion of anger from certain quarters of the American public, who immediately complain that such claims are nothing more than fallacious &amp;#x201C;appeals to authority,&amp;#x201D; sure signs of dreadful &amp;#x201C;elitism,&amp;#x201D; and an obvious effort to use credentials to stifle the dialogue required by a &amp;#x201C;real&amp;#x201D; democracy.&lt;/p&gt;&lt;/div&gt;																	
																		&lt;div&gt;
&lt;p&gt;But democracy, as &lt;a href=&quot;http://tomnichols.net/blog/2013/08/02/snowden-manning-and-screwtape/&quot;&gt;I wrote in an essay about C.S. Lewis and the Snowden affair&lt;/a&gt;, denotes a system of government, not an actual state of equality. It means that we enjoy equal rights versus the government, and in relation to each other. Having equal rights does not mean having equal talents, equal abilities, or equal knowledge.&amp;#xA0; It assuredly does not mean that &amp;#x201C;everyone&amp;#x2019;s opinion about anything is as good as anyone else&amp;#x2019;s.&amp;#x201D; And yet, this is now enshrined as the credo of a fair number of people despite being obvious nonsense.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;h2&gt;What&amp;#x2019;s going on here?&lt;/h2&gt;
&lt;p&gt;I fear we are witnessing the &amp;#x201C;death of expertise&amp;#x201D;: a Google-fueled, Wikipedia-based, blog-sodden collapse of any division between professionals and laymen, students and teachers, knowers and wonderers &amp;#x2013; in other words, between those of any achievement in an area and those with none at all. By this, I do not mean the death of actual expertise, the knowledge of specific things that sets some people apart from others in various areas. There will always be doctors, lawyers, engineers, and other specialists in various fields. Rather, what I fear has died is any acknowledgement of expertise as anything that should alter our thoughts or change the way we live.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p class=&quot;pull-right&quot;&gt;What has died is any acknowledgement of expertise as anything that should alter our thoughts or change the way we live.&lt;/p&gt;
&lt;p&gt;This is a very bad thing. Yes, it&amp;#x2019;s true that experts can make mistakes, as disasters from thalidomide to the Challenger explosion tragically remind us. But mostly, experts have a pretty good batting average compared to laymen: doctors, whatever their errors, seem to do better with most illnesses than faith healers or your Aunt Ginny and her special chicken gut poultice. To reject the notion of expertise, and to replace it with a sanctimonious insistence that every person has a right to his or her own opinion, is silly.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;Worse, it&amp;#x2019;s dangerous. The death of expertise is a rejection not only of knowledge, but of the ways in which we gain knowledge and learn about things. Fundamentally, it&amp;#x2019;s a rejection of science and rationality, which are the foundations of Western civilization itself. Yes, I said &amp;#x201C;Western civilization&amp;#x201D;: that paternalistic, racist, ethnocentric approach to knowledge that created the nuclear bomb, the Edsel, and New Coke, but which also keeps diabetics alive, lands mammoth airliners in the dark, and writes documents like the Charter of the United Nations.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;This isn&amp;#x2019;t just about politics, which would be bad enough. No, it&amp;#x2019;s worse than that: the perverse effect of the death of expertise is that without real experts, everyone is an expert on everything. To take but one horrifying example, we live today in an advanced post-industrial country that is now fighting a resurgence of whooping cough &amp;#x2014; a scourge nearly eliminated a century ago &amp;#x2014; merely because otherwise intelligent people have been second-guessing their doctors and refusing to vaccinate their kids after reading stuff written by people who know exactly zip about medicine. (Yes, I mean &lt;a href=&quot;http://thefederalist.com/2014/01/17/www.thenation.com/blog/175388/jenny-mccarthys-vaccination-fear-mongering-and-cult-false-equivalence&quot;&gt;people like Jenny McCarthy&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;In politics, too, the problem has reached ridiculous proportions. People in political debates no longer distinguish the phrase &amp;#x201C;you&amp;#x2019;re wrong&amp;#x201D; from the phrase &amp;#x201C;you&amp;#x2019;re stupid.&amp;#x201D; To disagree is to insult. To correct another is to be a hater. And to refuse to acknowledge alternative views, no matter how fantastic or inane, is to be closed-minded.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;h2&gt;How conversation became exhausting&lt;/h2&gt;
&lt;p&gt;Critics might dismiss all this by saying that everyone has a right to participate in the public sphere. That&amp;#x2019;s true. But every discussion must take place within limits and above a certain baseline of competence. And competence is sorely lacking in the public arena. People with strong views on going to war in other countries can barely find their own nation on a map; people who want to punish Congress for this or that law can&amp;#x2019;t name their own member of the House.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p class=&quot;pull&quot;&gt;People with strong views on going to war in other countries can barely find their own nation on a map.&lt;/p&gt;
&lt;p&gt;None of this ignorance stops people from arguing as though they are research scientists. Tackle a complex policy issue with a layman today, and you will get snippy and sophistic demands to show ever increasing amounts of &amp;#x201C;proof&amp;#x201D; or &amp;#x201C;evidence&amp;#x201D; for your case, even though the ordinary interlocutor in such debates isn&amp;#x2019;t really equipped to decide what constitutes &amp;#x201C;evidence&amp;#x201D; or to know it when it&amp;#x2019;s presented. The use of evidence is a specialized form of knowledge that takes a long time to learn, which is why articles and books are subjected to &amp;#x201C;peer review&amp;#x201D; and not to &amp;#x201C;everyone review,&amp;#x201D; but don&amp;#x2019;t tell that to someone hectoring you about the how things really work in Moscow or Beijing or Washington.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;This subverts any real hope of a conversation, because it is simply exhausting &amp;#x2014; at least speaking from my perspective as the policy expert in most of these discussions &amp;#x2014; to have to start from the very beginning of every argument and establish the merest baseline of knowledge, and then constantly to have to negotiate the rules of logical argument. (Most people I encounter, for example, have no idea what a non-sequitur is, or when they&amp;#x2019;re using one; nor do they understand the difference between generalizations and stereotypes.) Most people are already huffy and offended before ever encountering the substance of the issue at hand.&lt;br&gt;
Once upon a time &amp;#x2014; way back in the Dark Ages before the 2000s &amp;#x2014; people seemed to understand, in a general way, the difference between experts and laymen. There was a clear demarcation in political food fights, as objections and dissent among experts came from their peers &amp;#x2014; that is, from people equipped with similar knowledge. The public, largely, were spectators.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;This was both good and bad. While it strained out the kook factor in discussions (editors controlled their letters pages, which today would be called &amp;#x201C;moderating&amp;#x201D;), it also meant that sometimes public policy debate was too esoteric, conducted less for public enlightenment and more as just so much dueling jargon between experts.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p class=&quot;pull-right&quot;&gt;If experts go back to only talking to each other, that&amp;#x2019;s bad for democracy.&lt;/p&gt;
&lt;p&gt;No one &amp;#x2014; not me, anyway &amp;#x2014; wants to return to those days. I like the 21st century, and I like the democratization of knowledge and the wider circle of public participation. That greater participation, however, is endangered by the utterly illogical insistence that every opinion should have equal weight, because people like me, sooner or later, are forced to tune out people who insist that we&amp;#x2019;re all starting from intellectual scratch. (Spoiler: We&amp;#x2019;re not.) And if that happens, experts will go back to only talking to each other. And that&amp;#x2019;s bad for democracy.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;h2&gt;The downside of no gatekeepers&lt;/h2&gt;
&lt;p&gt;How did this peevishness about expertise come about, and how can it have gotten so immensely foolish?&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;Some of it is purely due to the globalization of communication. There are no longer any gatekeepers: the journals and op-ed pages that were once strictly edited have been drowned under the weight of self-publishable blogs. There was once a time when participation in public debate, even in the pages of the local newspaper, required submission of a letter or an article, and that submission had to be written intelligently, pass editorial review, and stand with the author&amp;#x2019;s name attached. Even then, it was a big deal to get a letter in a major newspaper.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;Now, anyone can bum rush the comments section of any major publication. Sometimes, that results in a free-for-all that spurs better thinking. Most of the time, however, it means that anyone can post anything they want, under any anonymous cover, and never have to defend their views or get called out for being wrong.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;Another reason for the collapse of expertise lies not with the global commons but with the increasingly partisan nature of U.S. political campaigns. There was once a time when presidents would win elections and then scour universities and think-tanks for a brain trust; that&amp;#x2019;s how Henry Kissinger, Samuel Huntington, Zbigniew Brzezinski and others ended up in government service while moving between places like Harvard and Columbia.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p class=&quot;pull&quot;&gt;This is the code of the samurai, not the intellectual, and it privileges the campaign loyalist over the expert.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.washingtonpost.com/wp-dyn/content/article/2009/04/12/AR2009041202260.html&quot;&gt;Those days are gone&lt;/a&gt;. To be sure, some of the blame rests with the increasing irrelevance of overly narrow research in the social sciences. But it is also because the primary requisite of seniority in the policy world is too often an answer to the question: &amp;#x201C;What did you do during the campaign?&amp;#x201D; This is the code of the samurai, not the intellectual, and it privileges the campaign loyalist over the expert.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;I have a hard time, for example, imagining that I would be called to Washington today in the way I was back in 1990, when the senior Senator from Pennsylvania asked a former U.S. Ambassador to the UN who she might recommend to advise him on foreign affairs, and she gave him my name. Despite the fact that I had no connection to Pennsylvania and had never worked on his campaigns, he called me at the campus where I was teaching, and later invited me to join his personal staff.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;Universities, without doubt, have to own some of this mess. The idea of telling students that professors run the show and know better than they do strikes many students as something like uppity lip from the help, and so many profs don&amp;#x2019;t do it. (One of the greatest teachers I ever had, James Schall, &lt;a href=&quot;http://thefederalist.com/2014/01/17/www.catholiceducation.org/articles/education/ed0003.html&quot;&gt;once wrote many years ago&lt;/a&gt; that &amp;#x201C;students have obligations to teachers,&amp;#x201D; including &amp;#x201C;trust, docility, effort, and thinking,&amp;#x201D; an assertion that would produce howls of outrage from the entitled generations roaming campuses today.) As a result, many academic departments are boutiques, in which the professors are expected to be something like intellectual valets. This produces nothing but a delusion of intellectual adequacy in children who should be instructed, not catered to.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;h2&gt;The confidence of the dumb&lt;/h2&gt;
&lt;p&gt;There&amp;#x2019;s also that immutable problem known as &amp;#x201C;human nature.&amp;#x201D; It has a name now: it&amp;#x2019;s called &lt;a href=&quot;http://www.psychologytoday.com/blog/evolved-primate/201006/when-ignorance-begets-confidence-the-classic-dunning-kruger-effect&quot;&gt;the Dunning-Kruger effect&lt;/a&gt;, which says, in sum, that the dumber you are, the more confident you are that you&amp;#x2019;re not actually dumb. And when you get invested in being aggressively dumb&amp;#x2026;well, the last thing you want to encounter are experts who disagree with you, and so you dismiss them in order to maintain your unreasonably high opinion of yourself. (There&amp;#x2019;s a lot of that loose on social media, especially.)&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;All of these are symptoms of the same disease: a manic reinterpretation of &amp;#x201C;democracy&amp;#x201D; in which everyone must have their say, and no one must be &amp;#x201C;disrespected.&amp;#x201D; (The verb to disrespect is one of the most obnoxious and insidious innovations in our language in years, because it really means &amp;#x201C;to fail to pay me the impossibly high requirement of respect I demand.&amp;#x201D;) This yearning for respect and equality, even&amp;#x2014;perhaps especially&amp;#x2014;if unearned, is so intense that it brooks no disagreement. It represents the full flowering of a therapeutic culture where self-esteem, not achievement, is the ultimate human value, and it&amp;#x2019;s making us all dumber by the day.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;Thus, at least some of the people who reject expertise are not really, as they often claim, showing their independence of thought. They are instead rejecting anything that might stir a gnawing insecurity that their own opinion might not be worth all that much.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;h2&gt;Experts: the servants, not masters, of a democracy&lt;/h2&gt;
&lt;p&gt;So what can we do? Not much, sadly, since this is a cultural and generational issue that will take a long time come right, if it ever does. Personally, I don&amp;#x2019;t think technocrats and intellectuals should rule the world: we had quite enough of that in the late 20th century, thank you, and it should be clear now that intellectualism makes for lousy policy without some sort of political common sense. Indeed, in an ideal world, experts are the servants, not the masters, of a democracy.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;But when citizens forgo their basic obligation to learn enough to actually govern themselves, and instead remain stubbornly imprisoned by their fragile egos and caged by their own sense of entitlement, experts will end up running things by default. That&amp;#x2019;s a terrible outcome for everyone.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;Expertise is necessary, and it&amp;#x2019;s not going away. Unless we return it to a healthy role in public policy, we&amp;#x2019;re going to have stupider and less productive arguments every day. So here, presented without modesty or political sensitivity, are some things to think about when engaging with experts in their area of specialization.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;ol&gt;
&lt;li&gt;We can all stipulate: the expert isn&amp;#x2019;t always right.&lt;/li&gt;
&lt;li&gt;But an expert is far more likely to be right than you are. On a question of factual interpretation or evaluation, it shouldn&amp;#x2019;t engender insecurity or anxiety to think that an expert&amp;#x2019;s view is likely to be better-informed than yours. (Because, likely, it is.)&lt;/li&gt;
&lt;li&gt;Experts come in many flavors. Education enables it, but practitioners in a field acquire expertise through experience; usually the combination of the two is the mark of a true expert in a field. But if you have neither education nor experience, you might want to consider exactly what it is you&amp;#x2019;re bringing to the argument.&lt;/li&gt;
&lt;li&gt;In any discussion, you have a positive obligation to learn at least enough to make the conversation possible. The University of Google doesn&amp;#x2019;t count. Remember: having a strong opinion about something isn&amp;#x2019;t the same as knowing something.&lt;/li&gt;
&lt;li&gt;And yes, your political opinions have value. Of course they do: you&amp;#x2019;re a member of a democracy and what you want is as important as what any other voter wants. As a layman, however, your political analysis, has far less value, and probably isn&amp;#x2019;t &amp;#x2014; indeed, almost certainly isn&amp;#x2019;t &amp;#x2014; as good as you think it is.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And how do I know all this? Just who do I think I am?&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;Well, of course: I&amp;#x2019;m an expert.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;
&lt;p&gt;&lt;em&gt;Tom Nichols is a professor of national security affairs at the U.S. Naval War College and an adjunct at the Harvard Extension School. He claims expertise in a lot of things, but his most recent book is No Use: Nuclear Weapons and U.S. National Security (Penn, 2014). &lt;strong&gt;The views expressed are entirely his own.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;                                                    
                                                                                                        
                                                    &lt;/div&gt;
</description>
<title>
The Death Of Expertise
</title>
</item>
<item>
<link>
http://www.eweek.com/security/java-primary-cause-of-91-percent-of-attacks-cisco.html
</link>
<description>
&lt;div&gt;&lt;div id=&quot;content&quot;&gt;
    
    
    
    
    
                    &lt;span class=&quot;graycolor&quot;&gt;
                By &lt;a href=&quot;http://www.eweek.com/cp/bio/Sean-Michael-Kerner/&quot; title=&quot;Sean Michael Kerner&quot; class=&quot;author&quot;&gt;Sean Michael Kerner&lt;/a&gt;            &lt;/span&gt; &amp;#xA0;|&amp;#xA0;
        &lt;span class=&quot;graycolor&quot;&gt;Posted 2014-01-16&lt;/span&gt;
    &lt;span class=&quot;hr-space&quot;&gt;&lt;a href=&quot;http://www.eweek.com/email/security/java-primary-cause-of-91-percent-of-attacks-cisco.html/&quot; rel=&quot;noindex,nofollow&quot;&gt;&lt;img src=&quot;http://www.eweek.com/images/email.jpg&quot; width=&quot;16&quot; alt=&quot;Email this article&quot; class=&quot;email&quot;&gt; Email&lt;/a&gt;&lt;/span&gt;
    &lt;span class=&quot;hr-space&quot;&gt;&lt;a href=&quot;http://www.eweek.com/print/security/java-primary-cause-of-91-percent-of-attacks-cisco.html/&quot; rel=&quot;noindex,nofollow&quot;&gt;&lt;img src=&quot;http://www.eweek.com/images/print.gif&quot; width=&quot;15&quot; alt=&quot;Print this article&quot; class=&quot;print&quot;&gt; Print&lt;/a&gt;&lt;/span&gt;
     
    
    
    
    
    
    
    
                &lt;div&gt;
                &lt;img src=&quot;http://www.eweek.com/imagesvr_ce/983/290x195emailsecurity2012.jpg&quot; width=&quot;290&quot; alt=&quot;Java main cause of attacks&quot; class=&quot;shadow&quot;&gt;            &lt;/div&gt;
                &lt;div class=&quot;article_body&quot;&gt;
                        &lt;h2&gt;&lt;/h2&gt;&lt;p&gt;Cisco's 2014 Annual Security Report points the blame at Oracle's Java for being a leading cause of security woes.&lt;/p&gt;
                There are many different risks and attacks that IT professionals had to deal with in 2013, but no one technology was more abused or more culpable that Java, according to Cisco's latest annual security report.
The &lt;a href=&quot;http://www.cisco.com/web/offers/lp/2014-annual-security-report/index.html&quot; target=&quot;_blank&quot;&gt;Cisco 2014 Annual Security Report&lt;/a&gt; found that Java represented 91 percent of all Indicators of Compromise (IOCs) in 2013.
What that means is that the final payload in observed attacks was a Java exploit, Levi Gundert, technical lead, Cisco Threat Research, Analysis, and Communications (TRAC), explained to &lt;em&gt;eWEEK&lt;/em&gt;.
The Java data comes into the Cisco threat report by way of the Sourcefire Vulnerability Research Team (VRT), which became part of Cisco in 2013 with the $2.7 billion &lt;a href=&quot;http://www.eweek.com/security/cisco-execs-sourcefire-deal-bolsters-security-portolio.html&quot; target=&quot;_blank&quot;&gt;acquisition&lt;/a&gt; of Sourcefire.
        
                
        &quot;I was surprised to see that the Java IOC number was 91 percent,&quot; Gundert said. &quot;There were a number of Java zero days that were used in various attacks, but there were also a ton of well-known Java vulnerabilities that were packaged into various exploit packs.&quot;
        
        Cisco isn't the only one that saw a high degree of Java exploit activity in 2013. Multiple vendors, including Hewlett-Packard and Kaspersky Lab, &lt;a href=&quot;http://www.eweek.com/security/java-attacks-surge-in-2013.html&quot; target=&quot;_blank&quot;&gt;reported &lt;/a&gt;a surge in Java attacks during 2013. Just yesterday, Oracle &lt;a href=&quot;http://www.eweek.com/security/oracle-patches-144-new-security-vulnerabilities-to-start-2014.html&quot; target=&quot;_blank&quot;&gt;updated Java&lt;/a&gt; yet again, this time for 51 vulnerabilities.
&quot;2013 really was the year of Java exploits,&quot; Gundert said.
Java exploits tend to have great success because people simply just aren't patching it regularly, Gundert said.
        
        Java is such a juicy target for the same reason it is popular with enterprises and developers: It's portable and works on any operating system.&amp;#xA0;
The challenge is that, with a large Java application, patching isn't always easy, as there is always the potential that the patch could break functionality within the application, Gundert said.
&quot;For business users, the challenge is more complex than just simply saying you need to patch,&quot; Gundert said.
Patching alone, however, isn't enough. There were a number of zero-day Java exploits in 2013&amp;#x2014;including an attack that &lt;a href=&quot;http://www.eweek.com/security/zero-day-exploit-enabled-cyber-attack-on-us-labor-department/&quot; target=&quot;_blank&quot;&gt;affected &lt;/a&gt;the U.S. Department of Labor&amp;#x2014;that were actively being exploited, before any patch was available.
Aside from just not using or disabling Java, which isn't always an option for enterprise users, Gundert has a few suggestions. At the top of the list is a need for some form of behavior detection that monitors a user's chain of events before they land on an exploit.
&quot;For example, is a user requesting a Web page that included obfuscated JavaScript, and is the user being redirected?&quot; Gundert asked.
Most legitimate Websites will not use hidden or obfuscated JavaScript,&amp;#xA0;and few will redirect users without authorization, he explained.
&lt;strong&gt;Overall 2013 Trends&lt;/strong&gt;
While the use of Java is a highlight of the Cisco report, there are other key data points, including the fact that the overall number of threats rose by 14 percent on a year-over-year basis.
Another surprising finding is that among a sample of 30 large, multinational company networks taken by Cisco, 100 percent of them at some point in 2013 visited a Website that hosts malware.
&quot;I was really surprised that the number was 100 percent,&quot; Gundert said. &quot;It speaks to the fact that it's not about when an organization will be compromised; it's more about how long it will take an organization to detect a compromise and if the remediation window can be shortened.&quot;
Adding to the security challenges enterprises faced in 2013 is a human resources issue. Cisco's report claims that in 2014 there will be 1 million fewer security professionals available than what is needed.
&quot;2013 was a bleak year, looking at the threat landscape,&quot; Gundert said. &quot;Regardless of the tools that you have, if you don't have the right people in place, effective security is going to be very difficult.&quot;
&lt;em&gt;Sean Michael Kerner is a senior editor at &lt;/em&gt;eWEEK&lt;em&gt; and &lt;/em&gt;InternetNews.com.&lt;em&gt; Follow him on Twitter&lt;a href=&quot;https://www.twitter.com/techjournalist&quot; target=&quot;_blank&quot;&gt; @TechJournalist&lt;/a&gt;&lt;/em&gt;.
&amp;#xA0;
&amp;#xA0;        
            &lt;/div&gt;
            
    
        
    
                
                    
            
            
      
    
        
    
    
    
    &lt;a name=&quot;comment_form&quot;&gt;&lt;/a&gt;

    
&lt;/div&gt;
            &lt;/div&gt;
</description>
<title>
Java Primary Cause of 91 Percent of Attacks: Cisco
</title>
</item>
<item>
<link>
https://lh5.googleusercontent.com/-dJsRfi7_Crw/Utl_miUi3II/AAAAAAAA8jM/2ODyIK015WI/s450-no/How+radians+work.gif
</link>
<description>

</description>
<title>
How Radians Work in 30 Seconds
</title>
</item>
<item>
<author>
Ron Amadeo
</author>
<link>
http://arstechnica.com/security/2014/01/malware-vendors-buy-chrome-extensions-to-send-adware-filled-updates/?
</link>
<description>
&lt;div class=&quot;article-content clearfix&quot; score=&quot;10.0&quot;&gt;
    
&lt;figure class=&quot;intro-image image center full-width&quot;&gt;
      &lt;img src=&quot;http://cdn.arstechnica.net/wp-content/uploads/2014/01/code-640x283.png&quot; width=&quot;640&quot;&gt;
  
  &lt;/figure&gt;
  &lt;p&gt;One of the coolest things about Chrome is the silent, automatic updates that always ensure that users are always running the latest version. While Chrome itself is updated automatically by Google, that update process also includes Chrome's extensions, which are updated by the extension owners. This means that it's up to the user to decide if the owner of an extension is trustworthy or not, since you are basically giving them permission to push new code out to your browser whenever they feel like it.&lt;/p&gt;
&lt;p&gt;To make matters worse, ownership of a Chrome extension can be &lt;em&gt;&lt;/em&gt;transferred to another party, and users are never informed when an ownership change happens. Malware and adware vendors have caught wind of this and have started showing up at the doors of extension authors, looking to buy their extensions. Once the deal is done and the ownership of the extension is transferred, the new owners can issue an ad-filled update over Chrome's update service, which sends the adware out to every user of that extension.&lt;/p&gt;
&lt;p&gt;We ought to clarify here that Google isn't explicitly responsible for such unwanted adware, but vendors are exploiting Google's extension system to create a subpar—and possibly dangerous—browsing experience. Ars has contacted Google for comment, but we haven't heard back yet. We'll update this article if we do.&lt;/p&gt;
&lt;figure class=&quot;image center full&quot; score=&quot;12.5&quot;&gt;&lt;img src=&quot;http://cdn.arstechnica.net/wp-content/uploads/2014/01/2014-01-17_14-20-38.png&quot; width=&quot;613&quot;&gt;&lt;figcaption class=&quot;caption&quot; score=&quot;20.0&quot;&gt;&lt;div class=&quot;caption-text&quot;&gt;User reviews for Add to Feedly complaining about the adware.&lt;/div&gt; &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;A &lt;a href=&quot;http://www.labnol.org/internet/sold-chrome-extension/28377/&quot;&gt;first-hand account&lt;/a&gt; of this, which was first spotted by &lt;a href=&quot;http://www.omgchrome.com/malware-buying-google-chrome-extensions/&quot;&gt;OMGChrome&lt;/a&gt;, was given by Amit Agarwal, developer of the &quot;&lt;a href=&quot;https://chrome.google.com/webstore/detail/add-to-feedly/ejkjjleifeeaccajkekdcckflfpenoen?hl=en&quot;&gt;Add to Feedly&lt;/a&gt;&quot; extension. One morning, Agarwal got an e-mail offering &quot;4 figures&quot; for the sale of his Chrome extension. The extension was only about an hour's worth of work, so Agarwal agreed to the deal, the money was sent over PayPal, and he transferred ownership of the extension to another Google account. A month later, the new extension owners released their first (and so far only) update, which injected adware on all webpages and started redirecting links. Chrome's extension auto-update mechanism silently pushed out the update to all 30,000 Add to Feedly users, and the ad revenue likely started rolling in. While Agarwal had no idea what the buyer's intention was when the deal was made, he later learned that he ended up selling his users to the wolves. The buyer was not after the Chrome extension, they were just looking for an easy attack vector in the extension's user base.&lt;/p&gt;
&lt;p&gt;This isn't a one-time event, either. About a month ago, I had a very simple Chrome extension called &quot;&lt;a href=&quot;https://chrome.google.com/webstore/detail/tweet-this-page/ppilhaolhbpfembaoedfdbkegfedfgip/reviews&quot;&gt;Tweet This Page&lt;/a&gt;&quot; suddenly transform into an ad-injecting machine and start hijacking Google searches. A quick search for the Chrome Web Store reveals several other extensions that reviewers say suddenly made a U-turn from useful extension to ad-injector. There is even an extension that purports to &lt;a href=&quot;https://chrome.google.com/webstore/detail/stop-extensions-from-inje/bjdaconoeojhhkdjndlelgklkmalleon&quot;&gt;stop other extensions&lt;/a&gt; from injecting ads. Injected ads &lt;a href=&quot;https://developers.google.com/chrome/web-store/program_policies&quot;&gt;are allowed&lt;/a&gt; in Chrome extensions, but Google's policy states that which app the ads are coming from must be clearly disclosed to the user, and they cannot interfere with any native ads or the functionality of the website.&lt;/p&gt;
&lt;figure class=&quot;image center large full-width&quot; score=&quot;12.5&quot;&gt;&lt;a href=&quot;http://cdn.arstechnica.net/wp-content/uploads/2014/01/2014-01-17_14-08-2114.png&quot; class=&quot;enlarge&quot;&gt;&lt;img src=&quot;http://cdn.arstechnica.net/wp-content/uploads/2014/01/2014-01-17_14-08-2114-640x203.png&quot; width=&quot;640&quot;&gt;&lt;/a&gt;&lt;figcaption class=&quot;caption&quot; score=&quot;17.5&quot;&gt;&lt;div class=&quot;caption-text&quot;&gt;&lt;a href=&quot;http://cdn.arstechnica.net/wp-content/uploads/2014/01/2014-01-17_14-08-2114.png&quot; class=&quot;enlarge&quot;&gt;Enlarge&lt;/a&gt; &lt;span class=&quot;sep&quot;&gt;/&lt;/span&gt; Code from Tweet This Page, which hijacks Google, Yahoo, and Bing results and redirects to searchgist.com.&lt;/div&gt; &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;span&gt;When malicious apps don't follow Google's disclosure policy, diagnosing something like this is extremely difficult. When Tweet This Page started spewing ads and malware into my browser&lt;/span&gt;&lt;span&gt;, the only &lt;/span&gt;initial&lt;span&gt; sign was that ads on the Internet had suddenly become much more intrusive, and many auto-played sound. The extension only started injecting ads a few days after it was installed in an attempt to make it more difficult to detect. After a while, Google search became useless, because every link would redirect to some other webpage. My initial thought was to take an inventory of every program I had installed recently—I never suspected an &lt;/span&gt;&lt;em&gt;update&lt;/em&gt;&lt;span&gt; would bring in malware. &lt;/span&gt;&lt;span&gt;I ran a ton of malware/virus scanners, and they all found nothing. I was only clued into the fact that Chrome was the culprit because the same thing started happening on &lt;/span&gt;&lt;span&gt;my Chromebook—if I didn't notice that, the next step would have probably been a full wipe of my computer. &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;The difficult part of this for users is that normal removal techniques will not work. Virus scanners are unlikely to flag ad-injecting JavaScript as malicious. Extensions are synced to your Google account, which means that even wiping out a computer and reinstalling the OS will not remove the malware—signing-in to Chrome will just download it again. The only way to be rid of the malware is to find the extension in chrome://extensions and remove it—and to make sure the removal gets propagated to your account and down to all your other devices. &lt;/span&gt;&lt;span&gt;Even when you have it narrowed down to Chrome, since nothing detects a malicious Chrome extension, the best course of action is to meticulously check the latest reviews of every extension and hope that someone else has figured out where the ads are coming from.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;What can users do to protect themselves? It's very hard to keep yourself in the loop with Chrome extension updates. Extensions usually don't have changelogs, and there is currently no way to disable extension auto-updating. One way to stay a least slightly informed of what is going on is to install an extension that will &lt;a href=&quot;https://chrome.google.com/webstore/detail/extensions-update-notifie/nlldbplhbaopldicmcoogopmkonpebjm?hl=en&quot;&gt;notify you&lt;/a&gt; when your other extensions get updated. Other than that, the only other option is to stop using extensions entirely, which is a little extreme. Just keep an eye on the simpler extensions from smaller extension makers—those are the ones &lt;span&gt;at most risk of being gobbled up by a malicious entity. Chrome will require your approval if an extension adds &lt;/span&gt;&lt;a href=&quot;http://developer.chrome.com/extensions/permission_warnings.html&quot;&gt;new permissions&lt;/a&gt;&lt;span&gt;, but the magic permission that allows ad-injecting is called &quot;access your data on all web pages,&quot; which many legitimate extensions already use. A malicious extension buyer could even look for an extension that already uses this permission so that their update will arouse the least suspicion among current users.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The reality, though, is that while it's extremely easy for a novice user to install an extension, it's nearly impossible for them to diagnose and remove an extension that has turned sour, and Chrome Sync will make sure that extension hangs around on all their devices for a long time. The author of Add to Feedly stated that his extension had around 30,000 users before it was sold and packed full of ads. Today, despite the flood of unhappy user reviews, the Chrome Web Store shows 31,548 users. Auto-updating from a trusted source is one thing, but when that user trust can be bought and sold—and extension ownership can change hands without the users being informed—something needs to be done.&lt;/p&gt;
    		&lt;/div&gt;
    
</description>
<title>
Adware vendors buy Chrome Extensions to send ad- and malware-filled updates
</title>
</item>
</channel>
</rss>
